{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLA-NLP-Lecture3-Recurrent-Neural-Networks-PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWLyOxY6tQkBMJ1hVc6Zmn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LxYuan0420/aws-machine-learning-university-accelerated-nlp/blob/master/colab_notebooks/MLA_NLP_Lecture3_Recurrent_Neural_Networks_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipX8S2vWeTag",
        "outputId": "55a31ece-0e5b-42ee-ac65-c8da77fc5dc9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV9zUIxHeTaj",
        "outputId": "b7378985-0a28-40e7-d60e-d383f1bdf19a"
      },
      "source": [
        "%cd \"/gdrive/MyDrive/Colab Notebooks/git/aws-machine-learning-university-accelerated-nlp/colab_notebooks\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/Colab Notebooks/git/aws-machine-learning-university-accelerated-nlp/colab_notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQPo0MOPev-I"
      },
      "source": [
        "**Machine Learning Accelerator - Natural Language Processing - Lecture 3**\r\n",
        "\r\n",
        "**Recurrent Neural Networks (RNNs) for the Product Review Problem - Classify Product Reviews as Positive or Not**\r\n",
        "\r\n",
        "In this exercise, we will learn how to use Recurrent Neural Networks.\r\n",
        "\r\n",
        "We will follow these steps:\r\n",
        "\r\n",
        "1. Reading the dataset\r\n",
        "1. Exploratory data analysis\r\n",
        "1. Train-validation dataset split\r\n",
        "1. Text processing and transformation\r\n",
        "1. Using GloVe Word Embeddings\r\n",
        "1. Training and validating model\r\n",
        "1. Improvement ideas\r\n",
        "\r\n",
        "Overall dataset schema:\r\n",
        "\r\n",
        "1. reviewText: Text of the review\r\n",
        "1. summary: Summary of the review\r\n",
        "1. verified: Whether the purchase was verified (True or False)\r\n",
        "1. time: UNIX timestamp for the review\r\n",
        "1. log_votes: Logarithm-adjusted votes log(1+votes)\r\n",
        "1. isPositive: Whether the review is positive or negative (1 or 0)\r\n",
        "**Important note: One big distinction betweeen the regular neural networks and RNNs is that RNNs work with sequential data. In our case, RNNs will help us with the text field. If we also want to consider other fields such as time, log_votes, verified, etc. , we need to use the regular neural networks with the RNN network.**\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fOBNyQ3fFsX"
      },
      "source": [
        "import re\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "from torch import nn, optim\r\n",
        "from torch.nn import BCEWithLogitsLoss \r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtLWvMKkfMkP"
      },
      "source": [
        "**1. Reading the dataset**\r\n",
        "\r\n",
        "(Go to top)\r\n",
        "\r\n",
        "Let's read the dataset below and fill-in the reviewText field. We will use this field as input to our ML model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmQtVaKVfQ1X"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "df = pd.read_csv('../data/examples/AMAZON-REVIEW-DATA-CLASSIFICATION.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "i6oV9Y1-fS4o",
        "outputId": "c8fcc387-2c94-454c-c082-57b479471316"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewText</th>\n",
              "      <th>summary</th>\n",
              "      <th>verified</th>\n",
              "      <th>time</th>\n",
              "      <th>log_votes</th>\n",
              "      <th>isPositive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PURCHASED FOR YOUNGSTER WHO\\nINHERITED MY \"TOO...</td>\n",
              "      <td>IDEAL FOR BEGINNER!</td>\n",
              "      <td>True</td>\n",
              "      <td>1361836800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unable to open or use</td>\n",
              "      <td>Two Stars</td>\n",
              "      <td>True</td>\n",
              "      <td>1452643200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Waste of money!!! It wouldn't load to my system.</td>\n",
              "      <td>Dont buy it!</td>\n",
              "      <td>True</td>\n",
              "      <td>1433289600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I attempted to install this OS on two differen...</td>\n",
              "      <td>I attempted to install this OS on two differen...</td>\n",
              "      <td>True</td>\n",
              "      <td>1518912000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I've spent 14 fruitless hours over the past tw...</td>\n",
              "      <td>Do NOT Download.</td>\n",
              "      <td>True</td>\n",
              "      <td>1441929600</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          reviewText  ... isPositive\n",
              "0  PURCHASED FOR YOUNGSTER WHO\\nINHERITED MY \"TOO...  ...        1.0\n",
              "1                              unable to open or use  ...        0.0\n",
              "2   Waste of money!!! It wouldn't load to my system.  ...        0.0\n",
              "3  I attempted to install this OS on two differen...  ...        0.0\n",
              "4  I've spent 14 fruitless hours over the past tw...  ...        0.0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vboMq67CfTlv"
      },
      "source": [
        "**2. Exploratory Data Analysis**\r\n",
        "\r\n",
        "(Go to top)\r\n",
        "\r\n",
        "Let's look at the range and distribution of log_votes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InqRhVNwfYXe",
        "outputId": "8edc86ef-20af-44b2-c39b-06c045c92061"
      },
      "source": [
        "df['isPositive'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    43692\n",
              "0.0    26308\n",
              "Name: isPositive, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Df18sY0fdJg",
        "outputId": "2b6a6fc6-b72c-4532-85b5-6024aad55d19"
      },
      "source": [
        "print(df.isna().sum())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "reviewText    11\n",
            "summary       14\n",
            "verified       0\n",
            "time           0\n",
            "log_votes      0\n",
            "isPositive     0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCLkDY3Vfetn"
      },
      "source": [
        "**3. Train-validation split**\r\n",
        "\r\n",
        "(Go to top)\r\n",
        "\r\n",
        "Let's split the dataset into training and validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-b9ZSowvfiJ2"
      },
      "source": [
        "train_text, val_text, train_label, val_label = train_test_split(df[\"reviewText\"].tolist(), df[\"isPositive\"].tolist(), test_size=0.1, shuffle=True, random_state=324)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ7D_Ze0ftkX"
      },
      "source": [
        "**4. Text processing and Transformation**\r\n",
        "\r\n",
        "We will apply the following processes here:\r\n",
        "\r\n",
        "1. Text cleaning: Simple text cleaning operations. We won't do stemming or lemmatization as our word vectors already cover different forms of words. We are using GloVe word embeddings for 6 billion words, phrases or punctuations in this example.\r\n",
        "1. Tokenization: Tokenizing all sentences\r\n",
        "1. Creating vocabulary: We will create a vocabulary of the tokens. In this vocabulary, tokens will map to unique ids, such as \"car\"->32, \"house\"->651, etc.\r\n",
        "1. Transforming text: Tokenized sentences will be mapped to unique ids. For example: [\"this\", \"is\", \"sentence\"] -> [13, 54, 412].\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U6B5MJLfypY",
        "outputId": "e17c2a9f-86fc-40fb-f4ac-6f93cd06d666"
      },
      "source": [
        "from collections import Counter\r\n",
        "import nltk, torchtext\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "\r\n",
        "nltk.download(\"punkt\")\r\n",
        "\r\n",
        "\r\n",
        "def cleanStr(text):\r\n",
        "    if isinstance(text, str) == False:\r\n",
        "        text = \"\"\r\n",
        "\r\n",
        "    text = text.lower().strip()\r\n",
        "    text = re.sub(\"\\s+\", \" \", text)\r\n",
        "    text = re.compile(\"<.*?>\").sub(\"\", text)\r\n",
        "    return text\r\n",
        "\r\n",
        "def tokenize(text):\r\n",
        "    tokens = []\r\n",
        "    text = cleanStr(text)\r\n",
        "    words = word_tokenize(text)\r\n",
        "    for word in words:\r\n",
        "        tokens.append(word)\r\n",
        "    return tokens\r\n",
        "\r\n",
        "def createVocabulary(text_list, min_freq):\r\n",
        "    all_tokens = []\r\n",
        "    for sentence in text_list:\r\n",
        "        all_tokens += tokenize(sentence)\r\n",
        "    \r\n",
        "    counter = Counter()\r\n",
        "    for token in all_tokens:\r\n",
        "        counter[token] += 1\r\n",
        "    \r\n",
        "    vocab = torchtext.vocab.Vocab(counter, min_freq=min_freq, specials=(\"<unk>\"))\r\n",
        "\r\n",
        "    return vocab\r\n",
        "\r\n",
        "def transformText(text, vocab, max_length):\r\n",
        "    token_arr = torch.zeros((max_length))\r\n",
        "    tokens = tokenize(text)[0:max_length]\r\n",
        "    for idx, token in enumerate(tokens):\r\n",
        "        try:\r\n",
        "            token_arr[idx] = vocab.stoi[token]\r\n",
        "        except:\r\n",
        "            token_arr[idx] = 0 \r\n",
        "    return token_arr"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHXNVwWCjU8M",
        "outputId": "dc7ae3c5-6226-4219-d71e-92f1e719e0f1"
      },
      "source": [
        "min_freq = 5\r\n",
        "max_length = 250\r\n",
        "\r\n",
        "print(\"Creating the vocabulary\")\r\n",
        "vocab = createVocabulary(train_text, min_freq)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating the vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7DwIrO5jgTn",
        "outputId": "2babf6df-0199-48f0-e5f2-d2408c8608bf"
      },
      "source": [
        "print(\"Transforming training texts\")\r\n",
        "train_text_transformed = torch.stack([transformText(text, vocab, max_length) for text in train_text])\r\n",
        "print(\"Transforming validation texts\")\r\n",
        "val_text_transformed = torch.stack([transformText(text, vocab, max_length) for text in val_text])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transforming training texts\n",
            "Transforming validation texts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH9mv_RXj0H4",
        "outputId": "a3552105-59d4-4a02-ef03-74a1c045995f"
      },
      "source": [
        "# print some words and ids\r\n",
        "print(f\"Vocab index for beatiful: {vocab.stoi['beautiful']}\")\r\n",
        "print(f\"Vocab index for xyzzzxc: {vocab.stoi['xyzzzxc']}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab index for beatiful: 1931\n",
            "Vocab index for xyzzzxc: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wRsin4AkFLQ"
      },
      "source": [
        "**5. Using pre-trained GloVe Word Embeddings**\r\n",
        "\r\n",
        "(Go to top)\r\n",
        "\r\n",
        "In this example, we will use GloVe word vectors. name='6B' dim=50 gives us 6 billion words/phrases vectors. Each word vector has 50 numbers in it. The following code shows how to get the word vectors and create an embedding matrix from them. We will connect our vocabulary indexes to the GloVe embedding with the get_vecs_by_tokens() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ3HekEumO1J",
        "outputId": "fb6a48ba-9396-4a00-c969-f36214a98f35"
      },
      "source": [
        "a = vocab.itos\r\n",
        "print(type(a))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "bifGj4GbkJRH",
        "outputId": "0fa37a94-09c8-4735-cfe1-1dca8e702f89"
      },
      "source": [
        "from torchtext.vocab import GloVe\r\n",
        "\r\n",
        "glove = GloVe(name=\"6B\", dim=50)\r\n",
        "embedding_matrix = glove.get_vecs_by_tokens(vocab.itos)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.35MB/s]                           \n",
            "100%|█████████▉| 398025/400000 [00:13<00:00, 29083.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-fef67e070c18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mglove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGloVe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"6B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vecs_by_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'GloVe' object has no attribute 'get_vecs_by_tokens'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI2d5dnIk77B"
      },
      "source": [
        "**6. Training and validation**\r\n",
        "\r\n",
        "(Go to top)\r\n",
        "\r\n",
        "We have processed our text data and also created our embedding matrixes from GloVe. Now, it is time to start the training process.\r\n",
        "\r\n",
        "We will set our parameters below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDccaOh5k-Oe"
      },
      "source": [
        "hidden_size = 12\r\n",
        "learning_rate = 0.01\r\n",
        "epochs = 15\r\n",
        "batch_size = 32\r\n",
        "\r\n",
        "num_embed = 50\r\n",
        "vocab_size = len(vocab.itos)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wu3B8uLlIz8"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\r\n",
        "\r\n",
        "train_label = torch.Tensor(train_label)\r\n",
        "val_label = torch.Tensor(val_label)\r\n",
        "train_dataset = TensorDataset(train_text_transformed, train_label) \r\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skuV7SYJmrcI"
      },
      "source": [
        "device = torch.device(\"cpu\") # use \"cuda:0\" if you are using GPU\r\n",
        "\r\n",
        "class Net(nn.Module):\r\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers=1):\r\n",
        "        super().__init__()\r\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\r\n",
        "        self.rnn = nn.RNN(embed_size, num_hiddens, num_layers=num_layers)\r\n",
        "        self.linear = nn.Linear(3000, 1)\r\n",
        "        self.act = nn.Sigmoid()\r\n",
        "\r\n",
        "    def forward(self, inputs):\r\n",
        "        embeddings = self.embedding(inputs)\r\n",
        "        outputs, _ = self.rnn(embeddings)\r\n",
        "        outs = self.linear(outputs.reshape(outputs.shape[0], -1))\r\n",
        "        return self.act(outs)\r\n",
        "    \r\n",
        "model = Net(vocab_size, num_embed, hidden_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ginizel7oX8w"
      },
      "source": [
        "model.embedding.weight.data.copy_(embedding_matrix)\r\n",
        "model.embedding.weight.requires_grad=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAj9vxwgomLg"
      },
      "source": [
        "trainer = torch.optim.SGD(model.parameters(), lr=learning_rate)\r\n",
        "cross_ent_loss = nn.BCEWithLogitsLoss(reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uIgt5SBoviw"
      },
      "source": [
        "import time\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "    start = time.time()\r\n",
        "    training_loss=0\r\n",
        "    for idx, (data, target) in enumerate(train_loader):\r\n",
        "        trainer.zero_grad()\r\n",
        "        \r\n",
        "        data = data.long().to(device)\r\n",
        "        target = target.to(device)\r\n",
        "\r\n",
        "        output = model(data)\r\n",
        "        L = cross_ent_loss(output.squeeze(1), target).sum()\r\n",
        "        training_loss += L\r\n",
        "\r\n",
        "        L.backward()\r\n",
        "        trainer.step()\r\n",
        "\r\n",
        "    # one epoch finish \r\n",
        "    val_predictions = model(val_text_transformed.long().to(device)).squeeze(1)\r\n",
        "    val_loss = cross_ent_loss(val_predictions, val_label).sum().item()\r\n",
        "\r\n",
        "    training_loss /= len(train_label)\r\n",
        "    val_loss /= len(val_label)\r\n",
        "\r\n",
        "    end = time.time()\r\n",
        "    print(\"Epoch %s. Train_loss %f Validation_loss %f Seconds %f\" % \\\r\n",
        "          (epoch, training_loss, val_loss, end-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U496wY84p6R5"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\r\n",
        "\r\n",
        "# Get validation predictions\r\n",
        "val_predictions = model(val_text_transformed.to(device).long())\r\n",
        "\r\n",
        "# Round predictions: 1 if pred>0.5, 0 otherwise\r\n",
        "val_predictions = np.round(val_predictions.detach().numpy())\r\n",
        "\r\n",
        "print(\"Classification Report\")\r\n",
        "print(classification_report(val_label.numpy(), val_predictions))\r\n",
        "print(\"Accuracy\")\r\n",
        "print(accuracy_score(val_label.numpy(), val_predictions))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}